# -*- coding: utf-8 -*-
"""NaiveBayesPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U3EHSc61enQyf32VQByHsiZ_vCqupRS5
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

#copied_path = "drive/My Drive/ML/Naive Bayes/data.csv"
copied_path = "/content/drive/My Drive/ML/Naive Bayes/data.csv"
data = pd.read_csv(copied_path)

data.head()
cols = [0]
data.drop(data.columns[cols], inplace=True, axis=1)

cols = list(data.columns.values) #Make a list of all of the columns in the df
cols.pop(cols.index('City')) #Remove b from list
cols.pop(cols.index('PCOS')) #Remove x from list
cols.pop(cols.index('PCOS_from'))
data = data[cols+['PCOS']]

data['PCOS'] = data['PCOS'].map(dict(Yes = 1, No = 0))

data.head()

x = data.drop('PCOS', axis = 1)
y = data['PCOS']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)

model=GaussianNB()
model.fit(x_train, y_train)

y_pred = model.predict(x_test)

y_pred

accuracy = accuracy_score(y_test, y_pred) * 100

accuracy

from sklearn.metrics import confusion_matrix

results = confusion_matrix(y_test, y_pred) 
     
print('Confusion Matrix :')
print(results)

# import csv
# import math
# import random

# def loadDataset(data):
#   dataset = data.values.tolist()
#   for x in range(len(dataset)-1):
#     for y in range(22):
#       dataset[x][y] = int(dataset[x][y])
  
#   return dataset

# def splitDataset(dataset, splitRatio):
#   trainSize = int(len(dataset) * splitRatio)
#   trainSet = []
#   copy = dataset  
  
#   while len(trainSet) < trainSize:
#     index = random.randrange(len(copy))
#     trainSet.append(copy.pop(index))
  
#   return [trainSet, copy]

# def separateByClass(dataset):
#   separated = {}
  
#   for i in range(len(dataset)):
#     vector = dataset[i]
#     if (vector[-1] not in separated):
#       separated[vector[-1]] = []
#       separated[vector[-1]].append(vector)
      
#   return separated

# def mean(numbers):
#   print("mean", numbers)
#   return sum(numbers)/float(len(numbers))

# def stdev(numbers):
#   print(len(numbers))
#   avg = mean(numbers)
#   variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)

#   return math.sqrt(variance)

# def summarize(dataset):
#   print(dataset)
#   summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]
#   del summaries[-1]

#   return summaries

# def summarizeByClass(dataset):
#   separated = separateByClass(dataset)
#   summaries = {}

#   for classValue, instances in separated.items():
#     summaries[classValue] = summarize(instances)
#     print("INS",isinstance)
  
#   return summaries

# def calculateProbability(x, mean, stdev):
#   exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))

#   return (1/(math.sqrt(2*math.pi)*stdev))*exponent

# def calculateClassProbabilities(summaries, inputVector):
#   probabilities = {}

#   for classValue, classSummaries in summaries.items():
#     probabilities[classValue] = 1
#     for i in range(len(classSummaries)):
#       mean, stdev = classSummaries[i]
#       x = inputVector[i]
#       probabilities[classValue] *= calculateProbability(x, mean, stdev)

#   return probabilities

# def predict(summaries, inputVector):
#   probabilities = calculateClassProbabilities(summaries, inputVector)
#   bestLabel, bestProb = None, -1

#   for classValue, probability in probabilities.items():
#     if bestLabel is None or probability > bestProb:
#       bestProb = probability
#       bestLabel = classValue

#   return bestLabel

# def getPredictions(summaries, testSet):
#   predictions = []
  
#   for i in range(len(testSet)):
#     result = predict(summaries, testSet[i])
#     predictions.append(result)

#   return predictions

# def getAccuracy(testSet, predictions):
#   correct = 0

#   for x in range(len(testSet)):
#     if testSet[x][-1] == predictions[x]:
#       correct += 1

#   return (correct/float(len(testSet)))*100.0

# # Python script for confusion matrix creation. 
# from sklearn.metrics import confusion_matrix 
# from sklearn.metrics import accuracy_score 
# from sklearn.metrics import classification_report

# def main():
#   trainingSet=[] 
#   testSet=[] 
#   split = 0.67  

#   dataset = loadDataset(data)

#   trainingSet, testSet = splitDataset(dataset, split)

#   print('Split {0} rows into train = {1} and test = {2} rows'.format(len(dataset),len(trainingSet),len(testSet)))

#   #prepare model
  
#   summaries = summarizeByClass(trainingSet)

#   #train model
#   predictions = getPredictions(summaries, testSet)
#   accuracy = getAccuracy(testSet, predictions)
#   print('Accuracy: {0}%'.format(accuracy))

#   #test model
#   predictions = getPredictions(summaries, testSet)
#   accuracy = getAccuracy(testSet, predictions)
#   print('Accuracy: {0}%'.format(accuracy))

#   actual = []

#   for x in range(len(testSet)): 
#     actual.append(testSet[x][-1])

#   results = confusion_matrix(actual, predictions) 
  
#   print('Confusion Matrix :')
#   print(results) 
#   print('Accuracy Score :',accuracy_score(actual, predictions) )
#   print('Report : ')
#   print(classification_report(actual, predictions) )
 
# main()